import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as l,a as e,d as i,e as n,o as r}from"./app-DRR9Yo7Y.js";const s="/assets/Kafka%20%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8%E7%BB%8F%E9%AA%8C.002-3LsNuMFD.png",o="/assets/Kafka%20%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8%E7%BB%8F%E9%AA%8C.003-CPCkRQT3.png",p="/assets/Kafka%20%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8%E7%BB%8F%E9%AA%8C.004-Bz8GXeC8.png",c="/assets/Kafka%20%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8%E7%BB%8F%E9%AA%8C.005-7YMP2V_s.png",d="/assets/Kafka%20%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8%E7%BB%8F%E9%AA%8C.006-ChopXOUK.png",h={};function g(k,t){return r(),l("div",null,[t[0]||(t[0]=e("h1",{id:"kafka-实践应用经验",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#kafka-实践应用经验"},[e("span",null,"Kafka 实践应用经验")])],-1)),t[1]||(t[1]=e("p",null,"本文总结了Kafka在实际应用中的关键问题及解决方案，包括消息语义、消息可靠性、消息顺序性等重要主题。",-1)),i(" more "),t[2]||(t[2]=n('<h2 id="一、消费消息的语义" tabindex="-1"><a class="header-anchor" href="#一、消费消息的语义"><span>一、消费消息的语义</span></a></h2><h3 id="_1-常见的消费语义" tabindex="-1"><a class="header-anchor" href="#_1-常见的消费语义"><span>1. 常见的消费语义</span></a></h3><p>对于消息一般有如下几种消费模式：</p><ol><li><strong>At most once 最多一次：</strong> 消息可能会丢失，但是绝对不会重复发送。适合对消息传递可靠性不高的场景，如日志记录。</li><li><strong>At least once 至少一次：</strong> 消息不会丢失，但是可能被重复发送处理，适合对消息传递可靠性有要求，但是能容忍消息重复的场景，如事件通知。</li><li><strong>Exactly once 精确一次：</strong> 消息不会丢失，也不会被重复发送，其适用于关键业务场景，需要严格保证消息处理一次且仅一次，如金融交易处理。</li></ol><p>对于不同的业务需求，选择的消费语义不同。</p><h3 id="_2-实现-精确一次-的困难" tabindex="-1"><a class="header-anchor" href="#_2-实现-精确一次-的困难"><span>2. 实现 精确一次 的困难</span></a></h3><p>消息队列组件一般实现的都是至少一次语义，也就是至少能消费一次。</p><p>只要消息进入了 Kafka，是很容易实现至少一次语义的，但是需要考虑消息重复发送的可能性。</p><p>但在 kafka 中进一步实现精确一次消费是非常困难的，因为后端的任何一个环节都要考虑故障情况：</p><ol><li>网络问题：网络延迟、中断....可能导致消息重复发送</li><li>并发处理：kafka支持并发消费，多个消费者可以同时消费一个topic，因此要有对应的同步机制和协调</li><li>消费者处理：消费者在消费消息的时候出现异常或者错误，导致消息处理失败，但是没有正确的处理这些异常情况，没有提交偏移量或者是一次失败了就不做了，没有重试机制，也可能导致消息重复消费</li></ol><h2 id="二、如何保证消息不丢失" tabindex="-1"><a class="header-anchor" href="#二、如何保证消息不丢失"><span>二、如何保证消息不丢失</span></a></h2><h3 id="_1-消息在什么环节可能发生丢失" tabindex="-1"><a class="header-anchor" href="#_1-消息在什么环节可能发生丢失"><span>1. 消息在什么环节可能发生丢失</span></a></h3><ol><li>生产阶段</li><li>存储阶段</li><li>消费阶段</li></ol><p>保证消息不丢失，就要保证在这 3 个阶段的消息不丢失。</p><p>![消息丢失环节示意图](../images/Kafka 20实践应用经验.001.jpeg)</p><h3 id="_2-生产阶段" tabindex="-1"><a class="header-anchor" href="#_2-生产阶段"><span>2. 生产阶段</span></a></h3><div class="hint-container warning"><p class="hint-container-title">结论</p><ul><li>Kafka本身是没有什么机制能保证生产一定成功的，需要有额外的确认机制才可以。</li><li>原因：这个环节是在数据进入消息队列之前，甚至可能因为某些原因都没发送过数据，所以不该由消息队列来保证，所以这个结论也不影响消息队列的可靠性。</li></ul></div><p><strong>在生产阶段要有重试和确认机制：</strong></p><ul><li><strong>确认机制：</strong> 由Kafka 存储阶段 配合 producer的 acks 参数 实现，确保消息的可靠接收。</li><li><strong>重试机制：</strong> 由Producer依据确认机制的反馈来实现，确保在发送失败时能够重新尝试发送消息。</li></ul><h3 id="_3-存储阶段" tabindex="-1"><a class="header-anchor" href="#_3-存储阶段"><span>3. 存储阶段</span></a></h3><p>存储数据不丢失，也就是进去消息队列之后的数据，是持久的，Kafka这种消息队列，是非常可靠的，只要写入了队列，就不会丢消息。</p><p>这个依托于持久化存储：Kafka的消息确认机制依赖存储阶段</p><p>一旦消息被写入并确认(根据所选的确认级别)，它就会被持久化存储到磁盘中。</p><p>这意味着即使系统发生故障或重启，已经确认的消息也不会丢失。它就可以被消费者至少消费一次。</p><p><strong>存储阶段的ACK机制，有写入策略配置：</strong></p><table><thead><tr><th style="text-align:center;">Acks</th><th style="text-align:center;">行为</th><th style="text-align:center;">可靠性</th><th style="text-align:center;">性能</th></tr></thead><tbody><tr><td style="text-align:center;">0</td><td style="text-align:center;">producer发送消息给broker后，不等待broker的确认消息。producer也就无法重试和确认信息是否发送成功</td><td style="text-align:center;">不可靠</td><td style="text-align:center;">最高</td></tr><tr><td style="text-align:center;">1（默认）</td><td style="text-align:center;">producer发送消息给broker后，等待leader节点的确认，但是不会等待所有follow的确认</td><td style="text-align:center;">相对可靠</td><td style="text-align:center;">比较高</td></tr><tr><td style="text-align:center;">All</td><td style="text-align:center;">只有所有的副本都成功写入消息后，producer才会收到确认</td><td style="text-align:center;">可靠</td><td style="text-align:center;">相对低一些</td></tr></tbody></table><p><strong>acks 参数的作用机制</strong></p><ul><li><strong>Producer发送消息</strong>：Producer将消息发送到Kafka集群中的目标分区的Leader节点。</li><li><strong>Leader节点处理消息</strong>：Leader节点接收到消息后，根据acks参数的配置，决定是否立即向Producer发送确认或者等待同步副本的确认。</li><li><strong>Follower节点同步数据</strong>：如果acks=all，Leader节点会等待所有同步副本（Follower节点）成功复制数据后，再向Producer发送确认。</li></ul><div class="hint-container info"><p class="hint-container-title">一些疑问（已解决）</p><ol><li>acks是producer端配置的，发送消息到leader节点后，leader会根据acks参数决定是否回发确认以及何时回发确认</li><li>acks参数是否是每次producer发送消息都要携带</li><li>要携带acks，那这个参数或者类似的参数等等....是携带在自定义的消息结构里面，也就是kafka 在应用层自定义的二进制协议</li></ol></div><h3 id="_4-消费阶段" tabindex="-1"><a class="header-anchor" href="#_4-消费阶段"><span>4. 消费阶段</span></a></h3><p>Kafka提供了偏移量管理功能：Kafka消费者通过提交每个分区的偏移量来跟踪已经消费的消息。</p><p>即使消费者在处理消息时发生故障，重新启动后它仍然可以从最后一个提交的偏移量处继续消费，确保消息至少被处理一次。</p><p>上面是<strong>自动提交</strong>，也可用<strong>手动提交</strong>，由 consumer 业务代码自己控制提交时机，主动调用提交函数。</p><figure><img src="'+s+'" alt="消费阶段示意图" tabindex="0" loading="lazy"><figcaption>消费阶段示意图</figcaption></figure><h2 id="三、如何保证消息不重复" tabindex="-1"><a class="header-anchor" href="#三、如何保证消息不重复"><span>三、如何保证消息不重复</span></a></h2><div class="hint-container warning"><p class="hint-container-title">结论</p><ul><li>光靠消息队列是做不到不重复消费的，要消息队列配合业务逻辑配合完成。由于网络波动，基本上不可能让消息真的不重复，本质上不重复是手段，不重复产生影响才是目的。</li></ul></div><h3 id="_1-发生重复消费的场景" tabindex="-1"><a class="header-anchor" href="#_1-发生重复消费的场景"><span>1. 发生重复消费的场景</span></a></h3><ol><li><strong>生产阶段：</strong> 发送时就重复了，比如网络波动，生产者重试发送，2次其实都发到了Broker</li><li><strong>存储阶段：</strong> 在Kafka中存储的阶段，是不会重复的</li><li><strong>消费阶段：</strong> 业务收到消息之后因为各种原因没有及时提交偏移，后面又拉到了相同消息</li></ol><h3 id="_2-常见防重实现思路" tabindex="-1"><a class="header-anchor" href="#_2-常见防重实现思路"><span>2. 常见防重实现思路</span></a></h3><p><strong>基于 redis：</strong></p><ol><li><strong>唯一标识符：</strong> 为每个消息分配一个全局唯一的标识符(如UUID)</li><li><strong>Redis set：</strong> 将已消费的消息ID存储在Redis的Set数据结构中。每次消费消息前，检查该消息ID是否已存在于Set中</li><li><strong>原子操作：</strong> 使用Redis的原子操作(如 SISMEMBER和 SADD)来检查和添加消息ID，确保操作的原子性</li></ol><p><strong>基于 mysql：</strong></p><ol><li><strong>唯一约束：</strong> 在MySQL表中为消息ID创建一个唯一约束</li><li><strong>INSERT IGNORE：</strong> 使用 INSERT IGNORE或 ON DUPLICATE KEY UPDATE 语句来尝试插入消息记录。如果消息ID已存在，则忽略或更新该记录</li><li><strong>事务：</strong> 在需要的情况下，使用事务来确保多个操作的原子性</li></ol><h3 id="_3-流量优化" tabindex="-1"><a class="header-anchor" href="#_3-流量优化"><span>3. 流量优化</span></a></h3><p>如果业务用mysql做存储，可以参考上面的防重处理思路，基于此可以再做一些小优化：</p><p>如果重复请求过多，mysql 会无辜的多承担这部分的压力，如果再加一层 redis 做缓存限流，会好很多。</p><figure><img src="'+o+'" alt="流量优化示意图" tabindex="0" loading="lazy"><figcaption>流量优化示意图</figcaption></figure><h2 id="四、如何保证消息准确消费一次" tabindex="-1"><a class="header-anchor" href="#四、如何保证消息准确消费一次"><span>四、如何保证消息准确消费一次</span></a></h2><h3 id="_1-简单实现" tabindex="-1"><a class="header-anchor" href="#_1-简单实现"><span>1. 简单实现</span></a></h3><p>消息不丢失 + 消息不重复 = 准确消费一次</p><figure><img src="'+p+'" alt="消息准确消费示意图" tabindex="0" loading="lazy"><figcaption>消息准确消费示意图</figcaption></figure><h2 id="五、如何保证消息有序" tabindex="-1"><a class="header-anchor" href="#五、如何保证消息有序"><span>五、如何保证消息有序</span></a></h2><h3 id="_1-什么场景需要有序" tabindex="-1"><a class="header-anchor" href="#_1-什么场景需要有序"><span>1. 什么场景需要有序</span></a></h3><ol><li><strong>电商订单处理</strong>： <ul><li>在电商系统中，用户的订单操作（下单、支付、取消等）需要按照时间顺序处理。比如，用户先下单再支付，如果消息顺序错乱，可能会导致支付消息先到而下单消息后到，从而引发逻辑错误。</li></ul></li><li><strong>金融交易系统</strong>： <ul><li>在股票交易或银行转账等金融系统中，交易操作必须严格按照时间顺序执行。任何顺序错乱可能导致账户数据不一致，甚至引发严重的金融风险。</li></ul></li></ol><figure><img src="'+c+'" alt="消息有序场景示意图" tabindex="0" loading="lazy"><figcaption>消息有序场景示意图</figcaption></figure><ol start="3"><li><strong>任务调度</strong>： <ul><li>在任务调度系统中，任务的执行顺序可能直接影响结果。例如，某些依赖性任务必须按特定顺序执行，顺序错乱可能导致依赖关系无法满足，任务失败。</li></ul></li></ol><h3 id="_2-思路1-业务单分区" tabindex="-1"><a class="header-anchor" href="#_2-思路1-业务单分区"><span>2. 思路1：业务单分区</span></a></h3><p>这是最简单的做法，就是根据业务确定分区，即每类业务自己一个分区，这样就可以实现业务消息有序。</p><p>具体而言，将业务所有消息都指定同一个分区Key，这样一来所有消息都会添加至同一个Partition，这样就达到了我们的目的。</p><p><strong>潜在的不足之处：</strong></p><p>在于这样做性能的扩展性就低了很多，当单个业务增长比较快，最后压力都给到了同一个Partition，无法发挥多Partition的优势，所以一般而言还会根据情况进一步地业务内分区。</p><h3 id="_3-思路2-业务内多分区" tabindex="-1"><a class="header-anchor" href="#_3-思路2-业务内多分区"><span>3. 思路2：业务内多分区</span></a></h3><div class="hint-container tip"><p class="hint-container-title">提示</p><p>类似数据库分表</p></div><h4 id="_3-1-子业务分区" tabindex="-1"><a class="header-anchor" href="#_3-1-子业务分区"><span>3.1 子业务分区</span></a></h4><ul><li><strong>大业务分区：</strong></li></ul><p>同一个团队下，可能有不同的服务，比如：金融服务，消息服务等，假设他们都要传递消息给消息队列，显然可以金融服务一个分区，消息服务一个分区。</p><ul><li><strong>大业务 ----&gt; 子业务：</strong><ul><li>金融服务分为：风控子业务一个分区，支付子业务一个分区</li><li>消息服务分为：短信通知分区，微信通知分区</li></ul></li></ul><h4 id="_3-2-客户分区" tabindex="-1"><a class="header-anchor" href="#_3-2-客户分区"><span>3.2 客户分区</span></a></h4><p>如果对于客户而言，数据是比较独立的，客户之间没什么交互，我们还可以按客户来分区。</p><p>比如消息是记录某个客户的减肥记录，里面包含了日期和减了多少斤，消费之后希望按投递的顺序记录进某个文件或数据库。</p><p>这种场景就是客户自己有序即可，客户不用关心别的客户减肥情况，也就是说客户之间不需要依赖。</p><p>符合这种场景的业务，就可以按客户来进行分区，比如最简单的，按用户id%100来分，这样就可以划出来100个分区，比如用户1001就用分区Key:user-mod-1，用户2002就用分区Key:user-mod-2</p><p><strong>缺点：</strong></p><p>这种方式有一个缺点，增减节点会对原有的路由分布会造成冲击。</p><p>比如原来9个分区，用户id是10，那算出来就是10 % 9 = 1 号分区。</p><p>假设增加一个分区，该用户就路由到 10 % 10= 0 号分区，也就是说，当节点增加或减少，原来的路由基本上是全乱了。</p><p><strong>扩展思路：引入 hash 槽</strong></p><p>每个节点负责一部分槽，用户id算出来在哪个槽，就去负载该槽的节点进行交互。</p><p><strong>大致实现思路：</strong></p><ol><li><strong>确定哈希函数</strong> ： <ul><li>选择一个合适的哈希函数来计算每个客户的哈希值。常用的哈希函数包括 MD5、SHA-1 或者 CRC32 等。</li></ul></li><li><strong>定义哈希槽</strong> ： <ul><li>确定哈希槽的数量（通常是一个固定的常量，比如 1024 或 2048）。这些哈希槽将用于将客户分配到不同的队列中。</li></ul></li><li><strong>计算哈希值并映射到哈希槽</strong> ： <ul><li>使用哈希函数计算客户 ID 的哈希值。</li><li>将哈希值取模哈希槽的数量，得到一个哈希槽编号（hash_slot = hash(customer_id) % num_slots）。</li></ul></li><li><strong>分配队列</strong> ： <ul><li>将每个哈希槽映射到一个特定的消息队列。这样，相同客户 ID 的消息总是会映射到同一个哈希槽，从而保证消息的有序性。</li></ul></li></ol><figure><img src="'+d+'" alt="哈希槽示意图" tabindex="0" loading="lazy"><figcaption>哈希槽示意图</figcaption></figure><h4 id="_3-3-大小客户分区" tabindex="-1"><a class="header-anchor" href="#_3-3-大小客户分区"><span>3.3 大小客户分区</span></a></h4><div class="hint-container tip"><p class="hint-container-title">提示</p><p>待补充内容</p></div>',83))])}const _=a(h,[["render",g],["__file","kafka-practice.html.vue"]]),m=JSON.parse('{"path":"/back-end/kafka/application/kafka-practice.html","title":"Kafka 实践应用经验","lang":"zh-CN","frontmatter":{"title":"Kafka 实践应用经验","description":"深入探讨Kafka在实际应用中的关键问题及解决方案","date":"2024-01-01T00:00:00.000Z","category":["消息队列"],"tag":["Kafka","最佳实践","消息队列"],"head":[["meta",{"property":"og:url","content":"https://kryiea.cn/back-end/kafka/application/kafka-practice.html"}],["meta",{"property":"og:site_name","content":"🧐kryiea"}],["meta",{"property":"og:title","content":"Kafka 实践应用经验"}],["meta",{"property":"og:description","content":"深入探讨Kafka在实际应用中的关键问题及解决方案"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-31T15:53:39.000Z"}],["meta",{"property":"article:tag","content":"Kafka"}],["meta",{"property":"article:tag","content":"最佳实践"}],["meta",{"property":"article:tag","content":"消息队列"}],["meta",{"property":"article:published_time","content":"2024-01-01T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-31T15:53:39.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Kafka 实践应用经验\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-01-01T00:00:00.000Z\\",\\"dateModified\\":\\"2025-03-31T15:53:39.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"kryiea\\",\\"url\\":\\"https://github.com/kryiea\\",\\"email\\":\\"kryieaa@outlook.com\\"}]}"]]},"headers":[{"level":2,"title":"一、消费消息的语义","slug":"一、消费消息的语义","link":"#一、消费消息的语义","children":[{"level":3,"title":"1. 常见的消费语义","slug":"_1-常见的消费语义","link":"#_1-常见的消费语义","children":[]},{"level":3,"title":"2. 实现 精确一次 的困难","slug":"_2-实现-精确一次-的困难","link":"#_2-实现-精确一次-的困难","children":[]}]},{"level":2,"title":"二、如何保证消息不丢失","slug":"二、如何保证消息不丢失","link":"#二、如何保证消息不丢失","children":[{"level":3,"title":"1. 消息在什么环节可能发生丢失","slug":"_1-消息在什么环节可能发生丢失","link":"#_1-消息在什么环节可能发生丢失","children":[]},{"level":3,"title":"2. 生产阶段","slug":"_2-生产阶段","link":"#_2-生产阶段","children":[]},{"level":3,"title":"3. 存储阶段","slug":"_3-存储阶段","link":"#_3-存储阶段","children":[]},{"level":3,"title":"4. 消费阶段","slug":"_4-消费阶段","link":"#_4-消费阶段","children":[]}]},{"level":2,"title":"三、如何保证消息不重复","slug":"三、如何保证消息不重复","link":"#三、如何保证消息不重复","children":[{"level":3,"title":"1. 发生重复消费的场景","slug":"_1-发生重复消费的场景","link":"#_1-发生重复消费的场景","children":[]},{"level":3,"title":"2. 常见防重实现思路","slug":"_2-常见防重实现思路","link":"#_2-常见防重实现思路","children":[]},{"level":3,"title":"3. 流量优化","slug":"_3-流量优化","link":"#_3-流量优化","children":[]}]},{"level":2,"title":"四、如何保证消息准确消费一次","slug":"四、如何保证消息准确消费一次","link":"#四、如何保证消息准确消费一次","children":[{"level":3,"title":"1. 简单实现","slug":"_1-简单实现","link":"#_1-简单实现","children":[]}]},{"level":2,"title":"五、如何保证消息有序","slug":"五、如何保证消息有序","link":"#五、如何保证消息有序","children":[{"level":3,"title":"1. 什么场景需要有序","slug":"_1-什么场景需要有序","link":"#_1-什么场景需要有序","children":[]},{"level":3,"title":"2. 思路1：业务单分区","slug":"_2-思路1-业务单分区","link":"#_2-思路1-业务单分区","children":[]},{"level":3,"title":"3. 思路2：业务内多分区","slug":"_3-思路2-业务内多分区","link":"#_3-思路2-业务内多分区","children":[{"level":4,"title":"3.1 子业务分区","slug":"_3-1-子业务分区","link":"#_3-1-子业务分区","children":[]},{"level":4,"title":"3.2 客户分区","slug":"_3-2-客户分区","link":"#_3-2-客户分区","children":[]},{"level":4,"title":"3.3 大小客户分区","slug":"_3-3-大小客户分区","link":"#_3-3-大小客户分区","children":[]}]}]}],"git":{"createdTime":1743436419000,"updatedTime":1743436419000,"contributors":[{"name":"kryiea","email":"1582877056@qq.com","commits":1}]},"readingTime":{"minutes":10.56,"words":3169},"filePathRelative":"back-end/kafka/application/kafka-practice.md","localizedDate":"2024年1月1日","excerpt":"\\n<p>本文总结了Kafka在实际应用中的关键问题及解决方案，包括消息语义、消息可靠性、消息顺序性等重要主题。</p>\\n"}');export{_ as comp,m as data};
